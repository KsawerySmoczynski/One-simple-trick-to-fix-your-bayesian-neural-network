activation:
  activation_name: "LeakyRELU"
  class_path: torch.nn.LeakyReLU
  init_args:
    negative_slope: 0.5
